{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StairPy \n",
    "\n",
    "Dimitrios Psaltos\n",
    "V1 11/30/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librarys\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import bokeh\n",
    "from scipy.stats import mode\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resample_data(y_accel, timestamps, new_fs):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Concatenate data and timestamps\n",
    "    name = y_accel.name\n",
    "    data = pd.DataFrame({'ts': timestamps.astype('datetime64[ms]'), name: y_accel})\n",
    "    data.set_index('ts', inplace=True)\n",
    "\n",
    "    # Resample data\n",
    "    resampled_data = pd.DataFrame(data[name].resample(new_fs).mean())\n",
    "\n",
    "    # Create resampled timestamp dataframe\n",
    "    resampled_timestamps = resampled_data.index\n",
    "\n",
    "    # Reset index of resampled data\n",
    "    resampled_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return resampled_data, resampled_timestamps\n",
    "\n",
    "def _cwt(y_accel, sample_rate, ic_prom, fc_prom, s_cwt1):\n",
    "    from scipy import signal, integrate\n",
    "    import pywt\n",
    "    import pandas as pd\n",
    "\n",
    "    # CWT wavelet scale parameters\n",
    "    scale_cwt1 = float(sample_rate) / s_cwt1 #5.0\n",
    "    scale_cwt2 = float(sample_rate) / 6.0\n",
    "\n",
    "    # Detrend data\n",
    "    detrended_data = signal.detrend(y_accel.accel_x)\n",
    "\n",
    "    # Low pass filter if less than 40 hz - Not working appropriately\n",
    "    if sample_rate >= 40:\n",
    "        filtered_data = _butter_lowpass_filter(detrended_data, sample_rate)\n",
    "    elif sample_rate < 40:\n",
    "        filtered_data = detrended_data\n",
    "\n",
    "    # cumulative trapezoidal integration\n",
    "    integrated_data = integrate.cumtrapz(-filtered_data)\n",
    "\n",
    "    # Gaussian continuous wavelet transform\n",
    "    cwt_1, freqs = pywt.cwt(integrated_data, scale_cwt1, 'gaus1')\n",
    "    differentiated_data = cwt_1[0]\n",
    "\n",
    "    # initial contact (heel strike) peak detection\n",
    "    ic_peaks, y_wav = _detect_peaks(pd.Series(-differentiated_data), ic_prom)\n",
    "\n",
    "    # Gaussian continuous wavelet transform\n",
    "    cwt_2, freqs = pywt.cwt(-differentiated_data, scale_cwt2, 'gaus1')\n",
    "    re_differentiated_data = cwt_2[0]\n",
    "\n",
    "    # final contact (toe off) peak detection\n",
    "    fc_peaks = _detect_peaks(pd.Series(re_differentiated_data), fc_prom)\n",
    "\n",
    "    ###plot\n",
    "    return ic_peaks, y_wav\n",
    "\n",
    "def _detect_peaks(y, prominence):\n",
    "    from scipy.signal import find_peaks\n",
    "    #peaks, properties = find_peaks(y, prominence=prominence)\n",
    "    peaks, properties = find_peaks(y, prominence=prominence) #30\n",
    "\n",
    "    return peaks, y\n",
    "\n",
    "def _butter_lowpass_filter(data, fs, cutoff=20, order=4):\n",
    "    from scipy import signal\n",
    "    b, a = _butter_lowpass(cutoff, fs, order=order)\n",
    "    filtered_signal = signal.filtfilt(b, a, data)\n",
    "    return filtered_signal\n",
    "\n",
    "def _butter_lowpass(cutoff, fs, order):\n",
    "    from scipy.signal import butter\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def get_height(subject):\n",
    "    csv = '/Users/psaltd/Desktop/StairClimb_results/stadiometer.csv'\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.sort_values('subject')\n",
    "    df['full_ID'] = ['%s1198%s' % (str(x)[:4], str(x)[4:]) for x in df.subject]\n",
    "    row = df[df.full_ID == subject]\n",
    "\n",
    "    return row.HT.iloc[0], row.WT.iloc[0]\n",
    "\n",
    "# def get_subject_weight(subject):\n",
    "#     weight_csv = '/Volumes/npru-bluesky/OtherProjects/PfIReLabStudy2/X9001198/Code/S3_download_20200318/raw/1001_SITEID/%s_USUBJID/01_VISITNUM/DEVDATA/Device_Tanita_Body_Impedance_Analysis_TANITABIA/%s_01_TANITABIA .csv' % (\n",
    "#     subject, subject)\n",
    "\n",
    "#     try:\n",
    "#         df = pd.read_csv(weight_csv, encoding='unicode_escape', usecols=[2, 5])\n",
    "#     except FileNotFoundError:\n",
    "#         weight_csv = '/Volumes/npru-bluesky/OtherProjects/PfIReLabStudy2/X9001198/Code/S3_download_20200318/raw/1001_SITEID/%s_USUBJID/01_VISITNUM/DEVDATA/Device_Tanita_Body_Impedance_Analysis_TANITABIA/%s_01_TANITABIA.csv' % (\n",
    "#         subject, subject)\n",
    "#         df = pd.read_csv(weight_csv, encoding='unicode_escape', usecols=[2, 5])\n",
    "\n",
    "#     df = df.dropna(axis=0)\n",
    "#     weight = df['Weight (kg)']  # in kg\n",
    "\n",
    "#     return weight\n",
    "\n",
    "def plot_steps(ytime, y_accel, peakst, peaksx, s, v, t, y_wav):\n",
    "    save_name = '%s_%s_%s_peak_detection.png' % (s, v, t)\n",
    "    ywav_time = ytime[:len(y_wav)]\n",
    "    plt.plot(ytime, y_accel, label = 'Y accel')\n",
    "    plt.plot(ywav_time, y_wav/5, label = 'cwt (scaled down 5x)')\n",
    "    plt.scatter(peakst, peaksx, color='red')\n",
    "    plt.title('subject %s, visit %s, task %s' % (s, v, t))\n",
    "    plt.legend()\n",
    "    plt.ylabel('accel (m/s^2)')\n",
    "    plt.xlabel('time (s)')\n",
    "\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n",
    "\n",
    "def stair_climb_power(subject, ic_t):\n",
    "    stepH = .1524 ##height in m\n",
    "    gravity = 9.81\n",
    "    h, mass = get_height(subject)\n",
    "    step_times = abs(np.diff(ic_t)) #in ns\n",
    "    step_times = step_times.astype('float')/1000000000\n",
    "\n",
    "    final_step_times = [x for x in step_times if x <= 1.20]#[x < 1.20 for x in step_times] #step time thresh 1.2s -- why is this? -- Visually inspected hist of step times\n",
    "    #Above this range was incorrect. Steps were skipped etc..\n",
    "\n",
    "    #add first step estimation to list\n",
    "    first_step = np.mean(final_step_times)\n",
    "\n",
    "    #final_step_times.append(first_step)\n",
    "\n",
    "    scp = mass * gravity * (stepH * len(final_step_times)) / (sum(final_step_times) + first_step)  \n",
    "    # to adjust for 1st step bias (mean of steptimes)\n",
    "    try:\n",
    "        return np.mean(scp), h, mass, first_step, len(final_step_times)\n",
    "    except (IndexError, ValueError):\n",
    "        return np.nan, np.nan, np.nan, np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StairPy(df, subject, visit, t):\n",
    "    '''\n",
    "    df = Dataframe raw data\n",
    "    '''\n",
    "    df.timestamp = pd.to_datetime(df.timestamp)\n",
    "\n",
    "    # Resample to 50Hz\n",
    "    res_x, timex = _resample_data(df.accel_x, df.timestamp, '0.02S')  # resample to 50Hz -- check with Matt\n",
    "    ic_peaks, y_wav = _cwt(res_x, 50, 27.1, 2, 11)\n",
    "    ic_x = res_x.iloc[np.array(ic_peaks)]\n",
    "    ic_t = timex[np.array(ic_peaks)]\n",
    "    plot_steps(timex, res_x, ic_t, ic_x, subject, visit, t, y_wav)\n",
    "    steps = len(ic_peaks) #- 1  #removing for the new prominance setting\n",
    "    try:\n",
    "        scp = stair_climb_power(subject, ic_t)\n",
    "    except KeyError:\n",
    "        print(subject, visit, t)\n",
    "    #if steps < 4:\n",
    "    #    print('error')\n",
    "    obj = {'subject': subject,\n",
    "           'visit': visit,\n",
    "           'trial': t,\n",
    "           'steps': steps,\n",
    "           'SCpower': scp[0].round(2),\n",
    "           'steps_detected': scp[-1],\n",
    "           'start_bout': df.timestamp.iloc[0],\n",
    "           'end_bout': df.timestamp.iloc[-1]\n",
    "           }\n",
    "    \n",
    "    results = pd.DataFrame([obj])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '100111980055_01_task3_U.csv'\n",
    "[subject, visit, task, end] = csv.split('_')\n",
    "t = task[-1]\n",
    "df = pd.read_csv(csv,\n",
    "             usecols=['time', 'accel_x', 'accel_y', 'accel_z',\n",
    "                      'gyro_x', 'gyro_y', 'gyro_z', 'timestamp'],\n",
    "             encoding='utf-8')\n",
    "results = StairPy(df, subject, visit, t)\n",
    "results.to_csv('%s_%s_%s_StairPy_results.csv' % (subject, visit, t), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
